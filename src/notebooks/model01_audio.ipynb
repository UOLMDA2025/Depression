{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e8d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from transformers.utils import logging as hf_logging\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    message=r\".*torch\\.utils\\._pytree\\._register_pytree_node.*\"\n",
    ")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.effects\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2ForSequenceClassification, get_linear_schedule_with_warmup, AutoProcessor\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, roc_auc_score\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "from scipy.signal import resample\n",
    "import random\n",
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, TimeStretch, Gain, HighPassFilter\n",
    "import noisereduce as nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75928673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "\n",
    "CHUNK_DURATION = 30\n",
    "CHUNK_STRIDE = 0.5\n",
    "SAMPLE_RATE = 16000\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 60\n",
    "LEARNING_RATE = 1e-6\n",
    "PATIENCE = 30\n",
    "MIN_DELTA = 0.001\n",
    "N_TRAIN_CHUNKS = 10\n",
    "CLASS_WEIGHTS = [1.0, 2.7]\n",
    "DROPOUT=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be7418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeder\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4dff530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label distribution:\n",
      " 0    77\n",
      "1    30\n",
      "\n",
      "Val label distribution:\n",
      " 0    23\n",
      "1    12\n",
      "\n",
      "Test label distribution:\n",
      " 0    33\n",
      "1    14\n"
     ]
    }
   ],
   "source": [
    "# Load CSVs and build label dicts\n",
    "\n",
    "train_file = pd.read_csv('00_dataset_daicwoz/train_split_Depression_AVEC2017.csv')\n",
    "val_file = pd.read_csv('00_dataset_daicwoz/dev_split_Depression_AVEC2017.csv')\n",
    "test_file = pd.read_csv('00_dataset_daicwoz/full_test_split.csv')\n",
    "\n",
    "train_label_dict = train_file.set_index('Participant_ID')['PHQ8_Binary'].to_dict()\n",
    "val_label_dict = val_file.set_index('Participant_ID')['PHQ8_Binary'].to_dict()\n",
    "test_label_dict = test_file.set_index('Participant_ID')['PHQ_Binary'].to_dict()\n",
    "\n",
    "print(\"Train label distribution:\\n\", pd.Series(list(train_label_dict.values())).value_counts().to_string(index=True))\n",
    "print(\"\\nVal label distribution:\\n\", pd.Series(list(val_label_dict.values())).value_counts().to_string(index=True))\n",
    "print(\"\\nTest label distribution:\\n\", pd.Series(list(test_label_dict.values())).value_counts().to_string(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c8c3511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files: 106, Val files: 35, Test files: 46\n"
     ]
    }
   ],
   "source": [
    "# Match audio files to train/val splits\n",
    "\n",
    "all_files = glob.glob(os.path.join(\"01_audio\", '*'))\n",
    "train_files, val_files, test_files = [], [], []\n",
    "\n",
    "for file in all_files:\n",
    "    basename = os.path.basename(file)\n",
    "    participant_id_str = basename.split('_')[0]\n",
    "    try:\n",
    "        participant_id = int(participant_id_str)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    if participant_id in train_label_dict:\n",
    "        train_files.append(file)\n",
    "    elif participant_id in val_label_dict:\n",
    "        val_files.append(file)\n",
    "    elif participant_id in test_label_dict:\n",
    "        test_files.append(file)\n",
    "\n",
    "print(f\"Train files: {len(train_files)}, Val files: {len(val_files)}, Test files: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28059e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class with chunk diversity and augmentation\n",
    "\n",
    "class AudioChunkDataset(Dataset):\n",
    "    def __init__(self, file_list, label_dict, chunk_duration, sample_rate, mode='train', n_chunks=1):\n",
    "        self.file_list = file_list\n",
    "        self.label_dict = label_dict\n",
    "        self.chunk_duration = chunk_duration\n",
    "        self.sample_rate = sample_rate\n",
    "        self.mode = mode\n",
    "        self.n_chunks = n_chunks\n",
    "        self.index_map = []\n",
    "\n",
    "        chunk_size = int(chunk_duration * sample_rate)\n",
    "        stride = int(chunk_size * CHUNK_STRIDE)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            self.augmenter = Compose([\n",
    "                AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.005, p=0.2),\n",
    "                Gain(min_gain_db=-5.0, max_gain_db=10.0, p=0.3),\n",
    "                PitchShift(min_semitones=-1, max_semitones=1, p=0.3),\n",
    "                TimeStretch(min_rate=0.90, max_rate=1.1, p=0.3),\n",
    "                HighPassFilter(min_cutoff_freq=100, max_cutoff_freq=300, p=0.4),\n",
    "            ])\n",
    "\n",
    "        for file_path in self.file_list:\n",
    "            y, sr = librosa.load(file_path, sr=sample_rate)\n",
    "            total_samples = len(y)\n",
    "\n",
    "            if self.mode == 'train':\n",
    "                for _ in range(n_chunks):\n",
    "                    self.index_map.append((file_path, None))\n",
    "            else:\n",
    "                starts = list(range(0, total_samples - chunk_size + 1, stride))\n",
    "                if not starts:\n",
    "                    starts = [0]\n",
    "                for i, _ in enumerate(starts):\n",
    "                    self.index_map.append((file_path, i))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path, chunk_idx = self.index_map[idx]\n",
    "        participant_id = int(os.path.basename(file_path).split('_')[0])\n",
    "        label = self.label_dict[participant_id]\n",
    "\n",
    "        y, sr = librosa.load(file_path, sr=self.sample_rate)\n",
    "        chunk_samples = int(self.chunk_duration * sr)\n",
    "\n",
    "        if len(y) < chunk_samples:\n",
    "            y = np.pad(y, (0, chunk_samples - len(y)))\n",
    "            start = 0\n",
    "        else:\n",
    "            if self.mode == 'train':\n",
    "                max_start = len(y) - chunk_samples\n",
    "                start = np.random.randint(0, max_start + 1)\n",
    "            else:\n",
    "                stride = int(chunk_samples * CHUNK_STRIDE)\n",
    "                start = chunk_idx * stride\n",
    "                start = min(start, len(y) - chunk_samples)\n",
    "\n",
    "        y = y[start:start + chunk_samples]\n",
    "        if self.mode != 'train':\n",
    "            y = nr.reduce_noise(y=y, sr=self.sample_rate)\n",
    "        y = self.normalize_volume(y)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            y = self.augmenter(samples=y, sample_rate=self.sample_rate)\n",
    "\n",
    "        return torch.tensor(y, dtype=torch.float32), label, participant_id\n",
    "    \n",
    "    def normalize_volume(self, y, target_dBFS=-20):\n",
    "        rms = np.sqrt(np.mean(y**2))\n",
    "        scalar = 10 ** (target_dBFS / 20) / (rms + 1e-6)\n",
    "        y = y * scalar\n",
    "        return np.clip(y, -1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1992302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model class for inference\n",
    "\n",
    "class Wav2Vec2Classifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "            \"facebook/wav2vec2-base\",\n",
    "            num_labels=2,\n",
    "            problem_type=\"single_label_classification\",\n",
    "            classifier_dropout=DROPOUT,\n",
    "            ignore_mismatched_sizes=True\n",
    "        )\n",
    "\n",
    "    def forward(self, input_values, attention_mask=None):\n",
    "        return self.model(input_values=input_values, attention_mask=attention_mask).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b18e238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function\n",
    "\n",
    "feature_extractor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    audios, labels, participant_ids = zip(*batch)\n",
    "    audios = [a.numpy() for a in audios]\n",
    "    inputs = feature_extractor(\n",
    "        audios,\n",
    "        sampling_rate=SAMPLE_RATE,\n",
    "        padding=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    participant_ids = torch.tensor(participant_ids, dtype=torch.long)\n",
    "    return {**inputs, \"labels\": labels, \"participant_ids\": participant_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa2279d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "\n",
    "train_dataset = AudioChunkDataset(train_files, train_label_dict, CHUNK_DURATION, SAMPLE_RATE, mode='train', n_chunks=N_TRAIN_CHUNKS)\n",
    "val_dataset = AudioChunkDataset(val_files, val_label_dict, CHUNK_DURATION, SAMPLE_RATE, mode='val')\n",
    "test_dataset = AudioChunkDataset(test_files, test_label_dict, CHUNK_DURATION, SAMPLE_RATE, mode='test')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b568bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=PATIENCE, min_delta=MIN_DELTA):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_value = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, value):\n",
    "        if self.best_value is None:\n",
    "            self.best_value = value\n",
    "        elif self.best_value - value > self.min_delta:\n",
    "            self.best_value = value\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc0385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\",\n",
    "    num_labels=2,\n",
    "    problem_type=\"single_label_classification\",\n",
    "    ignore_mismatched_sizes=True\n",
    ");\n",
    "model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52c2571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values\n",
    "\n",
    "class_weights = torch.tensor(CLASS_WEIGHTS, dtype=torch.float32).to(model.device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "total_steps = len(train_loader) * NUM_EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca656eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21e609df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculate chunk count: 100%|██████████████████████████████████████████████████████████| 106/106 [00:18<00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min chunk count: 26\n",
      "Max chunk count: 130\n",
      "average chunk count: 58.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Check chunk count\n",
    "\n",
    "def count_chunks(file_path, chunk_duration, sample_rate, stride_fraction):\n",
    "    y, sr = librosa.load(file_path, sr=sample_rate)\n",
    "    total_samples = len(y)\n",
    "    chunk_samples = int(chunk_duration * sample_rate)\n",
    "    stride_samples = int(chunk_samples * stride_fraction)\n",
    "\n",
    "    if total_samples < chunk_samples:\n",
    "        return 1\n",
    "    \n",
    "    return 1 + (total_samples - chunk_samples) // stride_samples\n",
    "\n",
    "chunk_counts = [\n",
    "    count_chunks(f, CHUNK_DURATION, SAMPLE_RATE, CHUNK_STRIDE)\n",
    "    for f in tqdm(train_files, desc=\"Calculate chunk count\")\n",
    "]\n",
    "\n",
    "print(f\"Min chunk count: {min(chunk_counts)}\")\n",
    "print(f\"Max chunk count: {max(chunk_counts)}\")\n",
    "print(f\"average chunk count: {sum(chunk_counts) / len(chunk_counts):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9955d0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb9d3059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model loaded from: 01_best_audio_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Best Values\n",
    "\n",
    "best_model_state = None\n",
    "best_macro_f1 = 0\n",
    "best_epoch = 0\n",
    "best_val_probs = None\n",
    "best_val_labels = None\n",
    "best_val_part_ids = None\n",
    "best_val_auroc = None\n",
    "best_threshold = 0.5\n",
    "\n",
    "filename_best = \"01_best_audio_model.pth\"\n",
    "try:    \n",
    "    checkpoint = torch.load(filename_best, map_location=\"cuda\", weights_only=False)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    best_model_state = checkpoint['model_state_dict']\n",
    "    best_macro_f1 = checkpoint['best_macro_f1']\n",
    "    best_threshold = checkpoint['best_threshold']\n",
    "    best_epoch = checkpoint['best_epoch']\n",
    "    best_val_probs = checkpoint['best_val_probs']\n",
    "    best_val_labels = checkpoint['best_val_labels']\n",
    "    best_val_part_ids = checkpoint['best_val_part_ids']\n",
    "    best_val_auroc = checkpoint['best_val_auroc']\n",
    "    \n",
    "    print(f\"Best Model loaded from: {filename_best}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Warning: {filename_best} not found. Starting without preloaded model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36de870b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████████████| 265/265 [02:36<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train loss: 0.5574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC: 0.6037\n",
      "Validation loss: 0.8547 (Macro F1=0.5813, threshold=0.73)\n",
      "Validation classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6679    0.6580    0.6629      1415\n",
      "           1     0.4943    0.5053    0.4997       936\n",
      "\n",
      "    accuracy                         0.5972      2351\n",
      "   macro avg     0.5811    0.5816    0.5813      2351\n",
      "weighted avg     0.5987    0.5972    0.5979      2351\n",
      "\n",
      "\n",
      "New best Model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████████████████████████████████████████████████████| 265/265 [02:37<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train loss: 0.5624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC: 0.5927\n",
      "Validation loss: 0.9561 (Macro F1=0.5606, threshold=0.78)\n",
      "Validation classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6470    0.6890    0.6674      1415\n",
      "           1     0.4787    0.4316    0.4539       936\n",
      "\n",
      "    accuracy                         0.5866      2351\n",
      "   macro avg     0.5628    0.5603    0.5606      2351\n",
      "weighted avg     0.5800    0.5866    0.5824      2351\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|████████████████████████████████████████████████████████████████████████| 265/265 [02:40<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train loss: 0.5230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC: 0.5778\n",
      "Validation loss: 1.0334 (Macro F1=0.5447, threshold=0.81)\n",
      "Validation classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6447    0.5746    0.6076      1415\n",
      "           1     0.4477    0.5214    0.4817       936\n",
      "\n",
      "    accuracy                         0.5534      2351\n",
      "   macro avg     0.5462    0.5480    0.5447      2351\n",
      "weighted avg     0.5663    0.5534    0.5575      2351\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████████████████████████████| 265/265 [02:41<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train loss: 0.5330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUROC: 0.5712\n",
      "Validation loss: 1.1044 (Macro F1=0.4845, threshold=0.81)\n",
      "Validation classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7089    0.2806    0.4020      1415\n",
      "           1     0.4316    0.8259    0.5669       936\n",
      "\n",
      "    accuracy                         0.4977      2351\n",
      "   macro avg     0.5703    0.5532    0.4845      2351\n",
      "weighted avg     0.5985    0.4977    0.4677      2351\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:  43%|██████████████████████████████▉                                         | 114/265 [01:08<01:30,  1.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs\u001b[38;5;241m.\u001b[39mlogits, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     17\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     19\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    650\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m _engine_run_backward(\n\u001b[1;32m    354\u001b[0m     tensors,\n\u001b[1;32m    355\u001b[0m     grad_tensors_,\n\u001b[1;32m    356\u001b[0m     retain_graph,\n\u001b[1;32m    357\u001b[0m     create_graph,\n\u001b[1;32m    358\u001b[0m     inputs,\n\u001b[1;32m    359\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    360\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    361\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training code\n",
    "\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        batch = {k: v.to(model.device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "        outputs = model(\n",
    "            input_values=batch[\"input_values\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            labels=None\n",
    "        )\n",
    "        loss = loss_fn(outputs.logits, batch[\"labels\"])\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} train loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_probs, all_preds, all_labels, all_part_ids = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(model.device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "            outputs = model(\n",
    "                input_values=batch[\"input_values\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                labels=None\n",
    "            )\n",
    "            loss = loss_fn(outputs.logits, batch[\"labels\"])\n",
    "            val_loss += loss.item()\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
    "            preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "            labels = batch[\"labels\"].cpu().numpy()\n",
    "            part_ids = batch[\"participant_ids\"].cpu().numpy()\n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "            all_part_ids.extend(part_ids)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    try:\n",
    "        auroc = roc_auc_score(all_labels, all_probs)\n",
    "    except ValueError:\n",
    "        auroc = float('nan')\n",
    "    print(f\"Validation AUROC: {auroc:.4f}\")\n",
    "\n",
    "    # Checking for best threshold\n",
    "    best_macro_f1_epoch = 0\n",
    "    best_thresh_epoch = 0.5\n",
    "    for thresh in np.arange(0.2, 0.81, 0.01):\n",
    "        tuned_preds = (np.array(all_probs) >= thresh).astype(int)\n",
    "        macro_f1 = f1_score(all_labels, tuned_preds, average='macro')\n",
    "        if macro_f1 > best_macro_f1_epoch:\n",
    "            best_macro_f1_epoch = macro_f1\n",
    "            best_thresh_epoch = thresh\n",
    "\n",
    "    tuned_preds = (np.array(all_probs) >= best_thresh_epoch).astype(int)\n",
    "    acc = accuracy_score(all_labels, tuned_preds)\n",
    "    macro_f1 = f1_score(all_labels, tuned_preds, average='macro')\n",
    "    print(f\"Validation loss: {avg_val_loss:.4f} (Macro F1={best_macro_f1_epoch:.4f}, threshold={best_thresh_epoch:.2f})\")\n",
    "    print(\"Validation classification report:\\n\", classification_report(all_labels, tuned_preds, digits=4))\n",
    "\n",
    "    # Checking if its the new best Model\n",
    "    if best_macro_f1_epoch > best_macro_f1:\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        best_macro_f1 = best_macro_f1_epoch\n",
    "        best_threshold = best_thresh_epoch\n",
    "        best_epoch = epoch + 1\n",
    "        best_val_probs = np.array(all_probs)\n",
    "        best_val_labels = np.array(all_labels)\n",
    "        best_val_part_ids = np.array(all_part_ids)\n",
    "        best_val_auroc = auroc\n",
    "        \n",
    "        checkpoint = {\n",
    "            'model_state_dict': best_model_state,\n",
    "            'best_macro_f1': best_macro_f1,\n",
    "            'best_threshold': best_threshold,\n",
    "            'best_epoch': best_epoch,\n",
    "            'best_val_probs': best_val_probs,\n",
    "            'best_val_labels': best_val_labels,\n",
    "            'best_val_part_ids': best_val_part_ids,\n",
    "            'best_val_auroc': best_val_auroc\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint, filename_best)\n",
    "\n",
    "        print(\"\\nNew best Model saved!\\n\")\n",
    "\n",
    "    early_stopping(avg_val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f023c748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading best model from epoch 1 (Macro F1=0.5813, threshold=0.73) for final evaluation...\n",
      "\n",
      "[Best Model] Validation AUROC: 0.6037\n",
      "[Best Model] Participant AUROC: 0.6848\n",
      "\n",
      "[Best Model] Participant-level classification report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7727    0.7391    0.7556        23\n",
      "           1     0.5385    0.5833    0.5600        12\n",
      "\n",
      "    accuracy                         0.6857        35\n",
      "   macro avg     0.6556    0.6612    0.6578        35\n",
      "weighted avg     0.6924    0.6857    0.6885        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reloading Best Model\n",
    "\n",
    "print(f\"Reloading best model from epoch {best_epoch} (Macro F1={best_macro_f1:.4f}, threshold={best_threshold:.2f}) for final evaluation...\")\n",
    "print(f\"\\n[Best Model] Validation AUROC: {best_val_auroc:.4f}\")\n",
    "\n",
    "participant_pred_chunks = defaultdict(list)\n",
    "participant_true_label = {}\n",
    "\n",
    "for prob, label, part_id in zip(best_val_probs, best_val_labels, best_val_part_ids):\n",
    "    participant_pred_chunks[part_id].append(prob)\n",
    "    participant_true_label[part_id] = label\n",
    "\n",
    "agg_preds, agg_labels, agg_probs = [], [], []\n",
    "for part_id in participant_pred_chunks:\n",
    "    chunk_probs = participant_pred_chunks[part_id]\n",
    "    mean_prob = np.mean(chunk_probs)\n",
    "    maj_pred = int(mean_prob >= best_threshold)\n",
    "    agg_preds.append(maj_pred)\n",
    "    agg_labels.append(participant_true_label[part_id])\n",
    "    agg_probs.append(mean_prob)\n",
    "\n",
    "agg_acc = accuracy_score(agg_labels, agg_preds)\n",
    "agg_macro_f1 = f1_score(agg_labels, agg_preds, average='macro')\n",
    "try:\n",
    "    agg_auroc = roc_auc_score(agg_labels, agg_probs)\n",
    "except ValueError:\n",
    "    agg_auroc = float('nan')\n",
    "\n",
    "print(f\"[Best Model] Participant AUROC: {agg_auroc:.4f}\")\n",
    "print(\"\\n[Best Model] Participant-level classification report:\\n\\n\", classification_report(agg_labels, agg_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading best model from epoch 11 (Macro F1=0.5615, threshold=0.31) for final evaluation...\n",
    "\n",
    "# [Best Model] Validation AUROC: 0.5611\n",
    "# [Best Model] Participant AUROC: 0.6667\n",
    "\n",
    "# [Best Model] Participant-level classification report:\n",
    "\n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#            0     0.8235    0.6087    0.7000        23\n",
    "#            1     0.5000    0.7500    0.6000        12\n",
    "\n",
    "#     accuracy                         0.6571        35\n",
    "#    macro avg     0.6618    0.6793    0.6500        35\n",
    "# weighted avg     0.7126    0.6571    0.6657        35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f83cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading best model from epoch 8 (Macro F1=0.5802, threshold=0.47) for final evaluation...\n",
    "\n",
    "# [Best Model] Validation AUROC: 0.5797\n",
    "# [Best Model] Participant AUROC: 0.6667\n",
    "\n",
    "# [Best Model] Participant-level classification report:\n",
    "\n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#            0     0.7826    0.7826    0.7826        23\n",
    "#            1     0.5833    0.5833    0.5833        12\n",
    "\n",
    "#     accuracy                         0.7143        35\n",
    "#    macro avg     0.6830    0.6830    0.6830        35\n",
    "# weighted avg     0.7143    0.7143    0.7143        35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3a39ed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test set with best model...\n",
      "\n",
      "[Test Set] Participant AUROC: 0.4241\n",
      "[Test Set] Participant Accuracy: 0.3261\n",
      "[Test Set] Participant Macro F1: 0.2676\n",
      "\n",
      "[Test Set] Participant-level classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0312    0.0606        32\n",
      "           1     0.3111    1.0000    0.4746        14\n",
      "\n",
      "    accuracy                         0.3261        46\n",
      "   macro avg     0.6556    0.5156    0.2676        46\n",
      "weighted avg     0.7903    0.3261    0.1866        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating on test set with best model...\")\n",
    "\n",
    "model.eval()\n",
    "test_probs, test_preds, test_labels, test_part_ids = [], [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(model.device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "        outputs = model(input_values=batch[\"input_values\"], attention_mask=batch[\"attention_mask\"])\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
    "        preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "        labels = batch[\"labels\"].cpu().numpy()\n",
    "        part_ids = batch[\"participant_ids\"].cpu().numpy()\n",
    "\n",
    "        test_probs.extend(probs)\n",
    "        test_preds.extend(preds)\n",
    "        test_labels.extend(labels)\n",
    "        test_part_ids.extend(part_ids)\n",
    "\n",
    "# Aggregate like in validation\n",
    "participant_pred_chunks = defaultdict(list)\n",
    "participant_true_label = {}\n",
    "\n",
    "for prob, label, part_id in zip(test_probs, test_labels, test_part_ids):\n",
    "    participant_pred_chunks[part_id].append(prob)\n",
    "    participant_true_label[part_id] = label\n",
    "\n",
    "agg_preds, agg_labels, agg_probs = [], [], []\n",
    "for part_id in participant_pred_chunks:\n",
    "    chunk_probs = participant_pred_chunks[part_id]\n",
    "    mean_prob = np.mean(chunk_probs)\n",
    "    maj_pred = int(mean_prob >= best_threshold)  # Use same threshold as validation\n",
    "    agg_preds.append(maj_pred)\n",
    "    agg_labels.append(participant_true_label[part_id])\n",
    "    agg_probs.append(mean_prob)\n",
    "\n",
    "# Metrics\n",
    "agg_acc = accuracy_score(agg_labels, agg_preds)\n",
    "agg_macro_f1 = f1_score(agg_labels, agg_preds, average='macro')\n",
    "try:\n",
    "    agg_auroc = roc_auc_score(agg_labels, agg_probs)\n",
    "except ValueError:\n",
    "    agg_auroc = float('nan')\n",
    "\n",
    "print(f\"\\n[Test Set] Participant AUROC: {agg_auroc:.4f}\")\n",
    "print(f\"[Test Set] Participant Accuracy: {agg_acc:.4f}\")\n",
    "print(f\"[Test Set] Participant Macro F1: {agg_macro_f1:.4f}\")\n",
    "print(\"\\n[Test Set] Participant-level classification report:\\n\")\n",
    "print(classification_report(agg_labels, agg_preds, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cc9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating on test set with best model...\n",
    "\n",
    "# [Test Set] Participant AUROC: 0.6004\n",
    "# [Test Set] Participant Accuracy: 0.6087\n",
    "# [Test Set] Participant Macro F1: 0.5893\n",
    "\n",
    "# [Test Set] Participant-level classification report:\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0     0.7917    0.5938    0.6786        32\n",
    "#            1     0.4091    0.6429    0.5000        14\n",
    "\n",
    "#     accuracy                         0.6087        46\n",
    "#    macro avg     0.6004    0.6183    0.5893        46\n",
    "# weighted avg     0.6752    0.6087    0.6242        46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb36ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating on test set with best model...\n",
    "\n",
    "# [Test Set] Participant AUROC: 0.6094\n",
    "# [Test Set] Participant Accuracy: 0.6304\n",
    "# [Test Set] Participant Macro F1: 0.6080\n",
    "\n",
    "# [Test Set] Participant-level classification report:\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0     0.8000    0.6250    0.7018        32\n",
    "#            1     0.4286    0.6429    0.5143        14\n",
    "\n",
    "#     accuracy                         0.6304        46\n",
    "#    macro avg     0.6143    0.6339    0.6080        46\n",
    "# weighted avg     0.6870    0.6304    0.6447        46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740230f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
